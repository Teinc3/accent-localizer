{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accent Localizer\n",
    "\n",
    "Read README.md for problem description."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(os.path.join('__dataset', 'validated_regions.tsv'), sep='\\t')\n",
    "# df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the spectrogram of an audio file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spectrogram(path, sampling_rate = 48000, display = True):\n",
    "    # Load an audio file as a floating point time series.\n",
    "    audio , _ = librosa.load(path, sr=sampling_rate)\n",
    "\n",
    "    # Short-time Fourier transform (STFT).\n",
    "    stft = abs(librosa.stft(audio))\n",
    "\n",
    "    # Convert an amplitude spectrogram to dB-scaled spectrogram.\n",
    "    spectrogram = librosa.amplitude_to_db(stft)\n",
    "\n",
    "    if display:\n",
    "        plt.figure(figsize=(9, 3))\n",
    "        librosa.display.specshow(spectrogram, sr=sampling_rate, x_axis='time', y_axis='log')\n",
    "        plt.colorbar()\n",
    "    return spectrogram\n",
    "\n",
    "\n",
    "# _ = get_spectrogram(os.path.join('__dataset', 'clips', df.iloc[0]['path']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract features using mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feature(path, sampling_rate = 48000):\n",
    "    features = []\n",
    "    audio, _ = librosa.load(path, sr=sampling_rate)\n",
    "\n",
    "    spectral_centroid = np.mean(librosa.feature.spectral_centroid(y=audio, sr=sampling_rate))\n",
    "    spectral_bandwidth = np.mean(librosa.feature.spectral_bandwidth(y=audio, sr=sampling_rate))\n",
    "    spectral_rolloff = np.mean(librosa.feature.spectral_rolloff(y=audio, sr=sampling_rate))\n",
    "    features.append(spectral_centroid)\n",
    "    features.append(spectral_bandwidth)\n",
    "    features.append(spectral_rolloff)\n",
    "    \n",
    "    mfcc = librosa.feature.mfcc(y=audio, sr=sampling_rate)\n",
    "    for el in mfcc:\n",
    "        features.append(np.mean(el))\n",
    "    \n",
    "    return np.asarray(features, dtype=float)\n",
    "\n",
    "# features = extract_feature(os.path.join('__dataset', 'clips', df.iloc[0]['path']))\n",
    "# print(features)\n",
    "# print(features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a new features file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new file named feature_regions.tsv\n",
    "\n",
    "def create_header():\n",
    "    header = ['path', 'region', 'spectral_centroid', 'spectral_bandwidth', 'spectral_rolloff']\n",
    "    for i in range(1, 21):\n",
    "        header.append(f'mfcc{i}')\n",
    "    return header\n",
    "\n",
    "# Check if the file exists\n",
    "if not os.path.exists(os.path.join('__dataset', 'feature_regions.tsv')):\n",
    "    header = create_header()\n",
    "    # Save the header to the new file\n",
    "    with open(os.path.join('__dataset', 'feature_regions.tsv'), 'w') as f:\n",
    "        f.write('\\t'.join(header) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add the new features to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ron\\AppData\\Local\\Temp\\ipykernel_4244\\3775851770.py:2: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_val = pd.read_csv(os.path.join('__dataset', 'validated_regions.tsv'), sep='\\t')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 42950 rows in 0:52:27.280885 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read the validated_regions.tsv file\n",
    "df_val = pd.read_csv(os.path.join('__dataset', 'validated_regions.tsv'), sep='\\t')\n",
    "\n",
    "# Read the feature_regions.tsv file\n",
    "df_feat = pd.read_csv(os.path.join('__dataset', 'feature_regions.tsv'), sep='\\t')\n",
    "\n",
    "# Check the last row of the feature_regions.tsv file where we left off\n",
    "# Locate the same row in the validated_regions.tsv file\n",
    "# Start from the next row\n",
    "start = 0\n",
    "if len(df_feat) > 0:\n",
    "    last_row = df_feat.iloc[-1]\n",
    "    for i, row in df_val.iterrows():\n",
    "        if row['path'] == last_row['path'] and row['region'] == last_row['region']:\n",
    "            start = i + 1\n",
    "            break\n",
    "\n",
    "# Extract features for each row in the validated_regions.tsv file\n",
    "now = datetime.now()\n",
    "try:\n",
    "    for i, row in df_val.iloc[start:].iterrows():\n",
    "        features = list()\n",
    "        features.append(row['path'])\n",
    "        features.append(row['region'])\n",
    "        features.extend(extract_feature(os.path.join('__dataset', 'clips', row['path'])))\n",
    "\n",
    "        # Convert the list to a pandas Series\n",
    "        features_series = pd.Series(features, index=df_feat.columns)\n",
    "        # Add this feature row to the feature_regions.tsv file\n",
    "        df_feat = pd.concat([df_feat, features_series.to_frame().T], ignore_index=True)\n",
    "\n",
    "    raise Exception('Done')\n",
    "except KeyboardInterrupt as e:\n",
    "    # Save the extracted features to the feature_regions.tsv file\n",
    "    if not df_feat.empty:\n",
    "        df_feat.to_csv(os.path.join('__dataset', 'feature_regions.tsv'), sep='\\t', index=False)\n",
    "    print(f'Processed {i} rows in {datetime.now() - now} seconds\\n{e}')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
